<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Support Vector Machine (SVM): Interactive Machine Learning Tutorial | Roarba Portal</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="Learn Support Vector Machine (SVM) with interactive visualization. Master classification and regression using kernel methods. Includes Python, C++, and C# implementations." />
    <meta name="keywords" content="support vector machine, svm algorithm, machine learning, classification, regression, kernel methods, hyperplane optimization, pattern recognition" />
    <meta name="author" content="Rodrigo Arce" />
    
    <!-- Open Graph / Social Media Tags -->
    <meta property="og:title" content="Support Vector Machine (SVM): Interactive Machine Learning Tutorial" />
    <meta property="og:description" content="Master Support Vector Machine algorithm with interactive visualization. Learn optimal hyperplane classification and kernel methods for machine learning." />
    <meta property="og:image" content="https://roarba.com/static/img/algorithms/svm.jpg" />
    <meta property="og:url" content="https://roarba.com/algorithms/machine-learning/svm.html" />
    <meta property="og:type" content="article" />
    
    <!-- Article Specific Meta Tags -->
    <meta property="article:published_time" content="2025-02-19" />
    <meta property="article:author" content="https://github.com/lVoidi" />
    <meta property="article:section" content="Algorithms" />
    <meta property="article:tag" content="Machine Learning" />
    <meta property="article:tag" content="Classification" />
    <meta property="article:tag" content="Data Science" />
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://roarba.com/algorithms/machine-learning/svm.html" />

    <!-- Schema.org markup for Google -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "TechArticle",
      "headline": "Support Vector Machine (SVM): Interactive Machine Learning Tutorial",
      "image": "https://roarba.com/static/img/algorithms/svm.jpg",
      "datePublished": "2025-02-19",
      "dateModified": "2025-02-19",
      "author": {
        "@type": "Person",
        "name": "Rodrigo Arce",
        "url": "https://github.com/lVoidi"
      },
      "publisher": {
        "@type": "Person",
        "name": "Rodrigo Arce",
        "url": "https://roarba.com"
      },
      "description": "Comprehensive guide to Support Vector Machine algorithm, featuring interactive visualization and implementations in multiple programming languages.",
      "articleBody": "Support Vector Machine (SVM) is a powerful supervised learning algorithm that finds optimal hyperplanes for classification and regression tasks, developed by Vladimir Vapnik at AT&T Bell Labs.",
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://roarba.com/algorithms/machine-learning/svm.html"
      },
      "about": {
        "@type": "SoftwareSourceCode",
        "programmingLanguage": ["Python", "C++", "C#"],
        "abstract": "Implementation of Support Vector Machine for classification and regression",
        "codeSampleType": "full"
      },
      "teaches": {
        "@type": "Text",
        "name": "Machine Learning",
        "description": "Learn how to implement and use Support Vector Machines for classification and regression tasks"
      },
      "educationalLevel": "Advanced",
      "timeRequired": "PT45M",
      "interactivityType": "mixed"
    }
    </script>
    
    <!-- CSS imports -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="../../static/css/style.css" rel="stylesheet">
    <link href="../../static/css/algorithms.css" rel="stylesheet">
    <link href="../../static/css/algorithm-page.css" rel="stylesheet">
    <link href="../../static/css/prism.css" rel="stylesheet">

    <!-- Icon -->
    <link rel="icon" href="../../static/img/icon.png" type="image/x-icon">

    <style>
        /* Estilos responsivos para la visualización */
        .visualization-container {
            width: 100%;
            max-width: 800px;
            margin: 0 auto;
            padding: 15px;
        }

        .visualization-controls {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 20px;
            justify-content: center;
        }

        .control-group {
            flex: 1;
            min-width: 200px;
            max-width: 300px;
        }

        .visualization-wrapper {
            background: var(--background-color);
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
        }

        #visualizer {
            width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }

        .visualization-info {
            margin-top: 15px;
            text-align: center;
        }

        /* Estilos responsivos para history box */
        .history-box {
            margin: 20px 0;
            padding: 20px;
            border-radius: 8px;
            background: var(--background-color);
        }

        .history-content {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }

        .history-image {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 0 auto;
        }

        @media (min-width: 768px) {
            .history-content {
                flex-direction: row;
                align-items: center;
            }

            .history-image {
                max-width: 300px;
            }
        }

        /* Ajustes para móviles pequeños */
        @media (max-width: 480px) {
            .visualization-controls {
                flex-direction: column;
                align-items: stretch;
            }

            .control-group {
                max-width: none;
            }

            .btn-lg {
                padding: 0.5rem 1rem;
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <div id="navbar-placeholder"></div>

    <main class="container my-4">
        <div class="row">
            <!-- Algorithm Info Card -->
            <div class="col-md-3">
                <div class="algorithm-info-card">
                    <h3>Quick Info</h3>
                    <div class="info-item">
                        <span class="info-label">Category:</span>
                        <span class="info-value">Machine Learning</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Time Complexity:</span>
                        <span class="info-value">O(n²) - O(n³)</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Space Complexity:</span>
                        <span class="info-value">O(n)</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">Input Type:</span>
                        <span class="info-value">Feature Vectors</span>
                    </div>
                </div>
            </div>

            <!-- Main Content -->
            <div class="col-lg-9">
                <div class="algorithm-content">
                    <h1>Support Vector Machine (SVM)</h1>
                    
                    <div class="algorithm-metadata">
                        <span class="category-tag">Machine Learning</span>
                        <span class="difficulty-tag">Hard</span>
                    </div>

                    <section class="algorithm-section">
                        <h2>Description</h2>
                        <p>
                            Support Vector Machine (SVM) is a supervised learning algorithm that can be used for both 
                            classification and regression tasks. SVM is particularly effective in high-dimensional spaces and 
                            is versatile thanks to the use of different kernel functions that allow finding optimal separating 
                            hyperplanes in transformed feature spaces.
                        </p>
                    </section>

                    <section class="algorithm-section">
                        <h2>How It Works</h2>
                        <ol>
                            <li>Data Preparation:
                                <ul>
                                    <li>Collection of labeled training data</li>
                                    <li>Feature normalization/standardization</li>
                                    <li>Selection of appropriate kernel function</li>
                                </ul>
                            </li>
                            <li>Training Process:
                                <ul>
                                    <li>Find the optimal hyperplane that maximizes the margin between classes</li>
                                    <li>Identify support vectors (points closest to the hyperplane)</li>
                                    <li>Optimize model parameters (C, gamma, etc.)</li>
                                </ul>
                            </li>
                            <li>Classification:
                                <ul>
                                    <li>Project new data into feature space</li>
                                    <li>Determine which side of the hyperplane points fall on</li>
                                    <li>Assign labels based on hyperplane position</li>
                                </ul>
                            </li>
                        </ol>
                    </section>

                    <section class="algorithm-section history-box">
                        <h2>History</h2>
                        <div class="history-content">
                            <img src="../../static/img/svm.jpg" alt="Support Vector Machine Illustration" class="history-image">
                            <p>
                                The SVM algorithm was developed by Vladimir Vapnik and colleagues at AT&T Bell Laboratories 
                                during the 1990s. The fundamental idea emerged from statistical learning theory and 
                                structural risk minimization. Since its introduction, SVM has been widely adopted in 
                                various applications, from text recognition to bioinformatics, establishing itself as one 
                                of the most robust and versatile algorithms in machine learning.
                            </p>
                        </div>
                    </section>

                    <section class="algorithm-section">
                        <h2>Visualization</h2>
                        <div class="visualization-container">
                            <div class="visualization-controls">
                                <div class="control-group">
                                    <button id="startBtn" class="btn btn-primary btn-lg w-100">
                                        <i class="fas fa-play"></i> Start
                                    </button>
                                    <button id="resetBtn" class="btn btn-secondary btn-lg w-100 mt-2">
                                        <i class="fas fa-undo"></i> Reset
                                    </button>
                                </div>
                                <div class="control-group">
                                    <label for="kernelSelect" class="form-label">Kernel Function:</label>
                                    <select id="kernelSelect" class="form-select form-select-lg">
                                        <option value="linear">Linear</option>
                                        <option value="rbf" selected>RBF (Gaussian)</option>
                                        <option value="poly">Polynomial</option>
                                    </select>
                                </div>
                            </div>
                            <div class="visualization-wrapper">
                                <canvas id="visualizer"></canvas>
                                <div class="visualization-info">
                                    <div id="currentStep" class="current-step">
                                        Select kernel function and click Start
                                    </div>
                                </div>
                            </div>
                        </div>
                    </section>

                    <section class="algorithm-section">
                        <h2>Implementation</h2>
                        <div class="implementation-tabs">
                            <ul class="nav nav-tabs" role="tablist">
                                <li class="nav-item">
                                    <a class="nav-link active" data-bs-toggle="tab" href="#python">Python</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" data-bs-toggle="tab" href="#cpp">C++</a>
                                </li>
                                <li class="nav-item">
                                    <a class="nav-link" data-bs-toggle="tab" href="#csharp">C#</a>
                                </li>
                            </ul>
                            <div class="tab-content">
                                <div class="tab-pane fade show active" id="python">
                                    <pre><code class="language-python">
import numpy as np
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

class SVM:
    def __init__(self, kernel='rbf', C=1.0):
        self.scaler = StandardScaler()
        self.svm = SVC(kernel=kernel, C=C)
    
    def fit(self, X, y):
        # Normalize the data
        X_scaled = self.scaler.fit_transform(X)
        # Train the model
        self.svm.fit(X_scaled, y)
    
    def predict(self, X):
        # Normalize input data
        X_scaled = self.scaler.transform(X)
        # Make prediction
        return self.svm.predict(X_scaled)
    
    def get_support_vectors(self):
        # Get support vectors
        return self.scaler.inverse_transform(
            self.svm.support_vectors_
        )

# Example usage
if __name__ == "__main__":
    # Generate sample data
    np.random.seed(0)
    X = np.random.randn(100, 2)
    y = (X[:, 0] + X[:, 1] > 0).astype(int)
    
    # Create and train the model
    svm = SVM(kernel='rbf', C=1.0)
    svm.fit(X, y)
    
    # Make predictions
    X_test = np.random.randn(10, 2)
    predictions = svm.predict(X_test)
    print("Predictions:", predictions)
                                    </code></pre>
                                </div>
                                <div class="tab-pane fade" id="cpp">
                                    <pre><code class="language-cpp">
#include <vector>
#include <cmath>
#include <random>
#include <algorithm>

class SVM {
private:
    double C;
    std::string kernel_type;
    std::vector<double> weights;
    double bias;
    std::vector<std::vector<double>> support_vectors;
    
    // RBF (Gaussian) kernel function
    double rbf_kernel(const std::vector<double>& x1, 
                     const std::vector<double>& x2, 
                     double gamma = 0.1) {
        double squared_norm = 0.0;
        for(size_t i = 0; i < x1.size(); ++i) {
            double diff = x1[i] - x2[i];
            squared_norm += diff * diff;
        }
        return std::exp(-gamma * squared_norm);
    }
    
    // Linear kernel function
    double linear_kernel(const std::vector<double>& x1, 
                        const std::vector<double>& x2) {
        double sum = 0.0;
        for(size_t i = 0; i < x1.size(); ++i) {
            sum += x1[i] * x2[i];
        }
        return sum;
    }
    
    // Calculate kernel based on selected type
    double kernel_function(const std::vector<double>& x1, 
                          const std::vector<double>& x2) {
        if(kernel_type == "rbf") {
            return rbf_kernel(x1, x2);
        }
        return linear_kernel(x1, x2);
    }

public:
    SVM(const std::string& kernel = "rbf", double c = 1.0) 
        : C(c), kernel_type(kernel), bias(0.0) {}
    
    void fit(const std::vector<std::vector<double>>& X, 
             const std::vector<int>& y, 
             int max_iterations = 100) {
        const int n = X.size();
        weights.resize(n, 0.0);
        
        bool changed;
        int iteration = 0;
        
        do {
            changed = false;
            for(int i = 0; i < n; ++i) {
                double Ei = predict(X[i]) - y[i];
                
                if((y[i] * Ei < -0.01 && weights[i] < C) ||
                   (y[i] * Ei > 0.01 && weights[i] > 0)) {
                    
                    // Randomly select second point
                    int j;
                    do {
                        j = rand() % n;
                    } while(j == i);
                    
                    double Ej = predict(X[j]) - y[j];
                    
                    // Save old values
                    double old_wi = weights[i];
                    double old_wj = weights[j];
                    
                    // Calculate bounds
                    double L = std::max(0.0, old_wj + old_wi - C);
                    double H = std::min(C, old_wj + old_wi);
                    
                    if(L == H) continue;
                    
                    // Calculate eta
                    double eta = 2 * kernel_function(X[i], X[j]) -
                                kernel_function(X[i], X[i]) -
                                kernel_function(X[j], X[j]);
                    
                    if(eta >= 0) continue;
                    
                    // Update weights
                    weights[j] = old_wj - y[j] * (Ei - Ej) / eta;
                    weights[j] = std::min(H, std::max(L, weights[j]));
                    
                    if(std::abs(weights[j] - old_wj) < 1e-5) continue;
                    
                    weights[i] = old_wi + y[i] * y[j] *
                                (old_wj - weights[j]);
                    
                    // Update bias
                    double b1 = bias - Ei - y[i] * (weights[i] - old_wi) *
                               kernel_function(X[i], X[i]) -
                               y[j] * (weights[j] - old_wj) *
                               kernel_function(X[i], X[j]);
                    
                    double b2 = bias - Ej - y[i] * (weights[i] - old_wi) *
                               kernel_function(X[i], X[j]) -
                               y[j] * (weights[j] - old_wj) *
                               kernel_function(X[j], X[j]);
                    
                    bias = (b1 + b2) / 2;
                    changed = true;
                }
            }
            ++iteration;
        } while(changed && iteration < max_iterations);
        
        // Save support vectors
        for(size_t i = 0; i < weights.size(); ++i) {
            if(weights[i] > 0) {
                support_vectors.push_back(X[i]);
            }
        }
    }
    
    double predict(const std::vector<double>& x) {
        return bias;
        double sum = 0.0;
        for(size_t i = 0; i < support_vectors.size(); ++i) {
            sum += weights[i] * kernel_function(x, support_vectors[i]);
        }
        return sum + bias;
    }
};

// Example usage
int main() {
    // Generate sample data
    std::vector<std::vector<double>> X = {
        {1, 2}, {2, 3}, {3, 1}, {-1, -2}, {-2, -1}, {-3, -2}
    };
    std::vector<int> y = {1, 1, 1, -1, -1, -1};
    
    // Create and train model
    SVM svm("rbf", 1.0);
    svm.fit(X, y);
    
    // Make predictions
    std::vector<double> test_point = {2, 2};
    double prediction = svm.predict(test_point);
    std::cout << "Prediction: " << (prediction > 0 ? 1 : -1) << std::endl;
    
    return 0;
}
                                    </code></pre>
                                </div>
                                <div class="tab-pane fade" id="csharp">
                                    <pre><code class="language-csharp">
using System;
using System.Collections.Generic;
using System.Linq;

public class SVM
{
    private double C;
    private string kernelType;
    private double[] weights;
    private double bias;
    private List<double[]> supportVectors;
    
    public SVM(string kernel = "rbf", double c = 1.0)
    {
        C = c;
        kernelType = kernel;
        bias = 0.0;
        supportVectors = new List<double[]>();
    }
    
    // RBF (Gaussian) kernel function
    private double RbfKernel(double[] x1, double[] x2, double gamma = 0.1)
    {
        double squaredNorm = x1.Zip(x2, (a, b) => a - b)
                              .Select(diff => diff * diff)
                              .Sum();
        return Math.Exp(-gamma * squaredNorm);
    }
    
    // Linear kernel function
    private double LinearKernel(double[] x1, double[] x2)
    {
        return x1.Zip(x2, (a, b) => a * b).Sum();
    }
    
    // Calculate kernel based on selected type
    private double KernelFunction(double[] x1, double[] x2)
    {
        return kernelType == "rbf" ? RbfKernel(x1, x2) : LinearKernel(x1, x2);
    }
    
    public void Fit(double[][] X, int[] y, int maxIterations = 100)
    {
        int n = X.Length;
        weights = new double[n];
        
        bool changed;
        int iteration = 0;
        
        do
        {
            changed = false;
            for(int i = 0; i < n; i++)
            {
                double Ei = Predict(X[i]) - y[i];
                
                if((y[i] * Ei < -0.01 && weights[i] < C) ||
                   (y[i] * Ei > 0.01 && weights[i] > 0))
                {
                    // Randomly select second point
                    Random rand = new Random();
                    int j;
                    do
                    {
                        j = rand.Next(n);
                    } while(j == i);
                    
                    double Ej = Predict(X[j]) - y[j];
                    
                    // Save old values
                    double oldWi = weights[i];
                    double oldWj = weights[j];
                    
                    // Calculate bounds
                    double L = Math.Max(0, oldWj + oldWi - C);
                    double H = Math.Min(C, oldWj + oldWi);
                    
                    if(L == H) continue;
                    
                    // Calculate eta
                    double eta = 2 * KernelFunction(X[i], X[j]) -
                                KernelFunction(X[i], X[i]) -
                                KernelFunction(X[j], X[j]);
                    
                    if(eta >= 0) continue;
                    
                    // Update weights
                    weights[j] = oldWj - y[j] * (Ei - Ej) / eta;
                    weights[j] = Math.Min(H, Math.Max(L, weights[j]));
                    
                    if(Math.Abs(weights[j] - oldWj) < 1e-5) continue;
                    
                    weights[i] = oldWi + y[i] * y[j] *
                                (oldWj - weights[j]);
                    
                    // Update bias
                    double b1 = bias - Ei - y[i] * (weights[i] - oldWi) *
                               KernelFunction(X[i], X[i]) -
                               y[j] * (weights[j] - oldWj) *
                               KernelFunction(X[i], X[j]);
                    
                    double b2 = bias - Ej - y[i] * (weights[i] - oldWi) *
                               KernelFunction(X[i], X[j]) -
                               y[j] * (weights[j] - oldWj) *
                               KernelFunction(X[j], X[j]);
                    
                    bias = (b1 + b2) / 2;
                    changed = true;
                }
            }
            iteration++;
        } while(changed && iteration < maxIterations);
        
        // Save support vectors
        for(int i = 0; i < weights.Length; i++)
        {
            if(weights[i] > 0)
            {
                supportVectors.Add(X[i]);
            }
        }
    }
    
    public double Predict(double[] x)
    {
        return supportVectors.Select((sv, i) => 
            weights[i] * KernelFunction(x, sv)).Sum() + bias;
    }
    
    // Example usage
    public static void Main()
    {
        // Generate sample data
        double[][] X = new double[][]
        {
            new double[] {1, 2},
            new double[] {2, 3},
            new double[] {3, 1},
            new double[] {-1, -2},
            new double[] {-2, -1},
            new double[] {-3, -2}
        };
        
        int[] y = new int[] {1, 1, 1, -1, -1, -1};
        
        // Create and train model
        SVM svm = new SVM("rbf", 1.0);
        svm.Fit(X, y);
        
        // Make predictions
        double[] testPoint = new double[] {2, 2};
        double prediction = svm.Predict(testPoint);
        Console.WriteLine($"Prediction: {(prediction > 0 ? 1 : -1)}");
    }
}
                                    </code></pre>
                                </div>
                            </div>
                        </div>
                    </section>
                </div>
            </div>
        </div>
    </main>

    <!-- JavaScript imports -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.24.1/components/prism-javascript.min.js"></script>
    <script src="../../static/js/navbar.js"></script>
    <script src="../../static/js/svm-visualization.js"></script>
</body>
</html> 